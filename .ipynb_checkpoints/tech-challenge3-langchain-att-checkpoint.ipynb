{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fine-tuning do Modelo Llama-3.2-1B com unsloth e LoRA\n",
                "\n",
                "Este notebook realiza o fine-tuning de um modelo Llama-3.2-1B utilizando quantização 4-bit e ajuste eficiente de parâmetros (PEFT) com LoRA. As etapas incluem o carregamento dos dados, configuração do modelo, definição dos argumentos de treinamento e a execução do fine-tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importação das bibliotecas necessárias\n",
                "import json\n",
                "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
                "from trl import SFTTrainer\n",
                "from transformers import TrainingArguments, AutoTokenizer\n",
                "\n",
                "# Se necessário, instale as dependências (descomente a linha abaixo)\n",
                "# !pip install unsloth trl transformers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definição dos parâmetros de configuração\n",
                "max_seq_length = 2048  # Comprimento máximo da sequência de tokens\n",
                "dtype = None  # Tipo de dados (None para usar o padrão)\n",
                "load_in_4bit = True  # Ativar quantização de 4 bits para economizar memória\n",
                "dataset_path = \"dataset_formatado.json\"  # Caminho para o conjunto de dados"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregamento do conjunto de dados\n",
                "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
                "    finetune_data = json.load(f)\n",
                "\n",
                "print(f\"Conjunto de dados carregado com {len(finetune_data)} exemplos.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregamento do modelo base - Llama-3.2-1B com quantização 4-bit\n",
                "model, tokenizer = FastLanguageModel.from_pretrained(\n",
                "    model_name = \"unsloth/llama-3.2-1b-bnb-4bit\",  # Usando o modelo Llama-3.2-1B\n",
                "    max_seq_length = max_seq_length,\n",
                "    dtype = dtype,\n",
                "    load_in_4bit = load_in_4bit\n",
                ")\n",
                "\n",
                "print(\"Modelo e tokenizer carregados com sucesso.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuração do PEFT com LoRA\n",
                "model = FastLanguageModel.get_peft_model(\n",
                "    model,\n",
                "    r = 16,  # Rank da decomposição LoRA - controla a capacidade de adaptação\n",
                "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
                "    lora_alpha = 16,  # Fator de escala para os pesos LoRA\n",
                "    lora_dropout = 0,  # Taxa de dropout para regularização\n",
                "    bias = \"none\",  # Não ajustar parâmetros de bias\n",
                "    use_gradient_checkpointing = \"unsloth\",  # Economiza memória durante o treinamento\n",
                "    random_state = 3407,  # Semente para reprodutibilidade\n",
                "    use_rslora = False,  # Não usar Rank-Stabilized LoRA\n",
                "    loftq_config = None  # Configuração LoftQ (não utilizada)\n",
                ")\n",
                "\n",
                "print(\"PEFT configurado com LoRA.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definição dos argumentos de treinamento\n",
                "training_args = TrainingArguments(\n",
                "    per_device_train_batch_size = 2,  # Tamanho do batch por dispositivo\n",
                "    gradient_accumulation_steps = 4,  # Acumular gradientes para simular batches maiores\n",
                "    warmup_steps = 5,  # Passos de aquecimento para a taxa de aprendizado\n",
                "    max_steps = 60,  # Número máximo de passos de treinamento\n",
                "    learning_rate = 2e-4,  # Taxa de aprendizado\n",
                "    fp16 = not is_bfloat16_supported(),  # Usar precisão mista FP16 se BF16 não for suportado\n",
                "    bf16 = is_bfloat16_supported(),  # Usar BF16 se suportado (mais eficiente em GPUs recentes)\n",
                "    logging_steps = 1,  # Frequência de registro de métricas\n",
                "    optim = \"adamw_8bit\",  # Otimizador quantizado para economia de memória\n",
                "    weight_decay = 0.01,  # Regularização L2\n",
                "    lr_scheduler_type = \"linear\",  # Decaimento linear da taxa de aprendizado\n",
                "    seed = 3407,  # Semente para reprodutibilidade\n",
                "    output_dir = \"outputs\"  # Diretório para salvar os checkpoints\n",
                ")\n",
                "\n",
                "print(\"Argumentos de treinamento definidos.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inicialização do treinador\n",
                "trainer = SFTTrainer(\n",
                "    model = model,  \n",
                "    tokenizer = tokenizer,\n",
                "    train_dataset = finetune_data,  # Conjunto de dados de treinamento\n",
                "    dataset_text_field = \"prompt\",  # Campo de texto nos dados\n",
                "    max_seq_length = max_seq_length,\n",
                "    dataset_num_proc = 2,  # Número de processos para processamento dos dados\n",
                "    packing = False,  # Não empacotar múltiplas sequências em um único exemplo\n",
                "    args = training_args\n",
                ")\n",
                "\n",
                "print(\"Treinador inicializado.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Execução do treinamento\n",
                "trainer_stats = trainer.train()\n",
                "\n",
                "print(\"Treinamento concluído.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Otimização do modelo para inferência\n",
                "FastLanguageModel.for_inference(model)\n",
                "\n",
                "print(\"Modelo otimizado para inferência.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Fine-tuning concluído com sucesso!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.x"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}